{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interleave(x, z, seed=None):\n",
    "    \"\"\" Interleave x and z dimension-wise.\n",
    "    Args:\n",
    "        x (n_samples, x_dim) array.\n",
    "        z (n_samples, z_dim) array.\n",
    "    Returns\n",
    "        An array of shape (n_samples, x_dim + z_dim) in which\n",
    "            the columns of x and z are interleaved at random.\n",
    "    \"\"\"\n",
    "    state = np.random.get_state()\n",
    "    np.random.seed(seed or int(time.time()))\n",
    "    total_ids = np.random.permutation(x.shape[1]+z.shape[1])\n",
    "    np.random.set_state(state)\n",
    "    out = np.zeros([x.shape[0], x.shape[1] + z.shape[1]])\n",
    "    out[:, total_ids[:x.shape[1]]] = x\n",
    "    out[:, total_ids[x.shape[1]:]] = z\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_besttree(x, y, z, cv_grid, logdim, verbose, prop_test):\n",
    "    \"\"\" Choose the best decision tree hyperparameters by\n",
    "    cross-validation. The hyperparameter to optimize is min_samples_split\n",
    "    (see sklearn's DecisionTreeRegressor).\n",
    "    Args:\n",
    "        x (n_samples, x_dim): Input data array.\n",
    "        y (n_samples, y_dim): Output data array.\n",
    "        z (n_samples, z_dim): Optional auxiliary input data.\n",
    "        cv_grid (list of floats): List of hyperparameter values to try.\n",
    "        logdim (bool): If True, set max_features to 'log2'.\n",
    "        verbose (bool): If True, print out extra info.\n",
    "        prop_test (float): Proportion of validation data to use.\n",
    "    Returns:\n",
    "        DecisionTreeRegressor with the best hyperparameter setting.\n",
    "    \"\"\"\n",
    "    xz_dim = x.shape[1] + z.shape[1]\n",
    "    max_features='log2' if (logdim and xz_dim > 10) else None\n",
    "    if cv_grid is None:\n",
    "        min_samples_split = 2\n",
    "    elif len(cv_grid) == 1:\n",
    "        min_samples_split = cv_grid[0]\n",
    "    else:\n",
    "        clf = DecisionTreeRegressor(max_features=max_features)\n",
    "        splitter = ShuffleSplit(n_splits=3, test_size=prop_test)\n",
    "        cv = GridSearchCV(estimator=clf, cv=splitter,\n",
    "            param_grid={'min_samples_split': cv_grid}, n_jobs=-1)\n",
    "        cv.fit(interleave(x, z), y)\n",
    "        min_samples_split = cv.best_params_['min_samples_split']\n",
    "    if verbose:\n",
    "        print('min_samples_split: {}.'.format(min_samples_split))\n",
    "    clf = DecisionTreeRegressor(max_features=max_features,\n",
    "        min_samples_split=min_samples_split)\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_error(data_and_i):\n",
    "    \"\"\" \n",
    "    A function used for multithreaded computation of the fcit test statistic.\n",
    "    data['x']: First variable.\n",
    "    data['y']: Second variable.\n",
    "    data['z']: Conditioning variable.\n",
    "    data['data_permutation']: Permuted indices of the data.\n",
    "    data['perm_ids']: Permutation for the bootstrap.\n",
    "    data['n_test']: Number of test points.\n",
    "    data['clf']: Decision tree regressor.\n",
    "    \"\"\"\n",
    "    data, i = data_and_i\n",
    "    x = data['x']\n",
    "    y = data['y']\n",
    "    z = data['z']\n",
    "    if data['reshuffle']:\n",
    "        perm_ids = np.random.permutation(x.shape[0])\n",
    "    else:\n",
    "        perm_ids = np.arange(x.shape[0])\n",
    "    data_permutation = data['data_permutation'][i]\n",
    "    n_test = data['n_test']\n",
    "    clf = data['clf']\n",
    "\n",
    "    x_z = interleave(x[perm_ids], z, seed=i)\n",
    "\n",
    "    clf.fit(x_z[data_permutation][n_test:], y[data_permutation][n_test:])\n",
    "    return mse(y[data_permutation][:n_test],\n",
    "        clf.predict(x_z[data_permutation][:n_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x, y, z=None, num_perm=8, prop_test=.1,\n",
    "    discrete=(False, False), plot_return=False, verbose=False,\n",
    "    logdim=False, cv_grid=[2, 8, 64, 512, 1e-2, .2, .4], **kwargs):\n",
    "    \"\"\" Fast conditional independence test, based on decision-tree regression.\n",
    "    See Chalupka, Perona, Eberhardt 2017 [arXiv link coming].\n",
    "    Args:\n",
    "        x (n_samples, x_dim): First variable.\n",
    "        y (n_samples, y_dim): Second variable.\n",
    "        z (n_samples, z_dim): Conditioning variable. If z==None (default),\n",
    "            then performs an unconditional independence test.\n",
    "        num_perm: Number of data permutations to estimate\n",
    "            the p-value from marginal stats.\n",
    "        prop_test (int): Proportion of data to evaluate test stat on.\n",
    "        discrete (bool, bool): Whether x or y are discrete.\n",
    "        plot_return (bool): If True, return statistics useful for plotting.\n",
    "        verbose (bool): Print out progress messages (or not).\n",
    "        logdim (bool): If True, set max_features='log2' in the decision tree.\n",
    "        cv_grid (list): min_impurity_splits to cross-validate when training\n",
    "            the decision tree regressor.\n",
    "    Returns:\n",
    "        p (float): The p-value for the null hypothesis\n",
    "            that x is independent of y.\n",
    "    \"\"\"\n",
    "    # Compute test set size.\n",
    "    n_samples = x.shape[0]\n",
    "    n_test = int(n_samples * prop_test)\n",
    "\n",
    "    if z is None:\n",
    "        z = np.empty([n_samples, 0])\n",
    "\n",
    "    if discrete[0] and not discrete[1]:\n",
    "        # If x xor y is discrete, use the continuous variable as input.\n",
    "        x, y = y, x\n",
    "    elif x.shape[1] < y.shape[1]:\n",
    "        # Otherwise, predict the variable with fewer dimensions.\n",
    "        x, y = y, x\n",
    "\n",
    "    # Normalize y to make the decision tree stopping criterion meaningful.\n",
    "    y = StandardScaler().fit_transform(y)\n",
    "\n",
    "    # Set up storage for true data and permuted data MSEs.\n",
    "    d0_stats = np.zeros(num_perm)\n",
    "    d1_stats = np.zeros(num_perm)\n",
    "    data_permutations = [\n",
    "        np.random.permutation(n_samples) for i in range(num_perm)]\n",
    "\n",
    "    # Compute mses for y = f(x, z), varying train-test splits.\n",
    "    clf = cv_besttree(x, y, z, cv_grid, logdim, verbose, prop_test=prop_test)\n",
    "    datadict = {\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'z': z,\n",
    "            'data_permutation': data_permutations,\n",
    "            'n_test': n_test,\n",
    "            'reshuffle': False,\n",
    "            'clf': clf,\n",
    "            }\n",
    "    d1_stats = np.array(joblib.Parallel(n_jobs=-1, max_nbytes=100e6)(\n",
    "        joblib.delayed(obtain_error)((datadict, i)) for i in range(num_perm)))\n",
    "\n",
    "    # Compute mses for y = f(x, reshuffle(z)), varying train-test splits.\n",
    "    if z.shape[1] == 0:\n",
    "        x_indep_y = x[np.random.permutation(n_samples)]\n",
    "    else:\n",
    "        x_indep_y = np.empty([x.shape[0], 0])\n",
    "    clf = cv_besttree(x_indep_y, y, z, cv_grid, logdim,\n",
    "                      verbose, prop_test=prop_test)\n",
    "    datadict['reshuffle'] = True\n",
    "    datadict['x'] = x_indep_y\n",
    "    d0_stats = np.array(joblib.Parallel(n_jobs=-1, max_nbytes=100e6)(\n",
    "        joblib.delayed(obtain_error)((datadict, i)) for i in range(num_perm)))\n",
    "\n",
    "    if verbose:\n",
    "        np.set_printoptions(precision=3)\n",
    "        print('D0 statistics: {}'.format(d0_stats))\n",
    "        print('D1 statistics: {}\\n'.format(d1_stats))\n",
    "\n",
    "    # Compute the p-value (one-tailed t-test\n",
    "    # that mean of mse ratios equals 1).\n",
    "    t, p_value = ttest_1samp(d0_stats / d1_stats, 1)\n",
    "    if t < 0:\n",
    "        p_value = 1 - p_value / 2\n",
    "    else:\n",
    "        p_value = p_value / 2\n",
    "\n",
    "    if plot_return:\n",
    "        return (p_value, d0_stats, d1_stats)\n",
    "    else:\n",
    "        return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(1000, 1)\n",
    "y = np.random.randn(1000, 1)\n",
    "\n",
    "pval_i = test(x, y) # p-value should be uniform on [0, 1].\n",
    "pval_d = test(x, x + y) # p-value should be very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pval_i:  0.04295936160811521\n",
      "pval_d:  0.002320322021323675\n"
     ]
    }
   ],
   "source": [
    "print(\"pval_i: \", pval_i)\n",
    "print(\"pval_d: \", pval_d) # as expected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "z = np.random.dirichlet(alpha=np.ones(2), size=n_samples)\n",
    "x = np.vstack([np.random.multinomial(20, p) for p in z]).astype(float)\n",
    "y = np.vstack([np.random.multinomial(20, p) for p in z]).astype(float)\n",
    "\n",
    "# Check that x and y are dependent (p-value should be uniform on [0, 1]).\n",
    "pval_d = test(x, y)\n",
    "# Check that z d-separates x and y (the p-value should be small).\n",
    "pval_i = test(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
