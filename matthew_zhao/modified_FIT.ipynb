{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports \n",
    "\n",
    "#utilities\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "#stat tools\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from hyppo.ksample import Hotelling\n",
    "\n",
    "#regressors\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "#cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't need to change these\n",
    "\n",
    "#for concat of x and z \n",
    "def interleave(x, z, seed=None):\n",
    "    \"\"\" Interleave x and z dimension-wise.\n",
    "    Args:\n",
    "        x (n_samples, x_dim) array.\n",
    "        z (n_samples, z_dim) array.\n",
    "    Returns\n",
    "        An array of shape (n_samples, x_dim + z_dim) in which\n",
    "            the columns of x and z are interleaved at random.\n",
    "    \"\"\"\n",
    "    state = np.random.get_state()\n",
    "    np.random.seed(seed or int(time.time()))\n",
    "    total_ids = np.random.permutation(x.shape[1]+z.shape[1])\n",
    "    np.random.set_state(state)\n",
    "    out = np.zeros([x.shape[0], x.shape[1] + z.shape[1]])\n",
    "    out[:, total_ids[:x.shape[1]]] = x\n",
    "    out[:, total_ids[x.shape[1]:]] = z\n",
    "    return out\n",
    "\n",
    "#computes MSE\n",
    "def obtain_error(data_and_i):\n",
    "    \"\"\" \n",
    "    A function used for multithreaded computation of the fcit test statistic.\n",
    "    data['x']: First variable.\n",
    "    data['y']: Second variable.\n",
    "    data['z']: Conditioning variable.\n",
    "    data['data_permutation']: Permuted indices of the data.\n",
    "    data['perm_ids']: Permutation for the bootstrap.\n",
    "    data['n_test']: Number of test points.\n",
    "    data['clf']: Decision tree regressor.\n",
    "    \"\"\"\n",
    "    data, i = data_and_i\n",
    "    x = data['x']\n",
    "    y = data['y']\n",
    "    z = data['z']\n",
    "    if data['reshuffle']:\n",
    "        perm_ids = np.random.permutation(x.shape[0])\n",
    "    else:\n",
    "        perm_ids = np.arange(x.shape[0])\n",
    "    data_permutation = data['data_permutation'][i]\n",
    "    n_test = data['n_test']\n",
    "    clf = data['clf']\n",
    "\n",
    "    x_z = interleave(x[perm_ids], z, seed=i)\n",
    "\n",
    "    clf.fit(x_z[data_permutation][n_test:], y[data_permutation][n_test:])\n",
    "    return mse(y[data_permutation][:n_test],\n",
    "        clf.predict(x_z[data_permutation][:n_test]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(x, y, z, cv_grid, verbose, model, prop_test):\n",
    "    \"\"\" Choose the best decision tree hyperparameters by\n",
    "    cross-validation. The hyperparameter to optimize is min_samples_split\n",
    "    (see sklearn's DecisionTreeRegressor).\n",
    "    Args:\n",
    "        x (n_samples, x_dim): Input data array.\n",
    "        y (n_samples, y_dim): Output data array.\n",
    "        z (n_samples, z_dim): Optional auxiliary input data.\n",
    "        cv_grid (list): List of hyperparameter values to try in CV.\n",
    "        regresor (sklearn classifier): Which regression model to use.\n",
    "        prop_test (float): Proportion of validation data to use.\n",
    "    Returns:\n",
    "        DecisionTreeRegressor with the best hyperparameter setting.\n",
    "    \"\"\"\n",
    "    \n",
    "    splitter = ShuffleSplit(n_splits=3, test_size=prop_test)\n",
    "    cv = GridSearchCV(estimator=model, cv=splitter,\n",
    "            param_grid=cv_grid, n_jobs=-1)\n",
    "    cv.fit(interleave(x, z), y)\n",
    "    \n",
    "    return type(model)(**cv.best_params_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x, y, model, cv_grid, ksamp_test=None, z=None, num_perm=8, prop_test=.1,\n",
    "    discrete=(False, False), plot_return=False, verbose=False, **kwargs):\n",
    "    \"\"\" Fast conditional independence test, based on decision-tree regression.\n",
    "    See Chalupka, Perona, Eberhardt 2017 [arXiv link coming].\n",
    "    Args:\n",
    "        x (n_samples, x_dim): First variable.\n",
    "        y (n_samples, y_dim): Second variable.\n",
    "        z (n_samples, z_dim): Conditioning variable. If z==None (default),\n",
    "            then performs an unconditional independence test.\n",
    "        num_perm: Number of data permutations to estimate\n",
    "            the p-value from marginal stats.\n",
    "        prop_test (int): Proportion of data to evaluate test stat on.\n",
    "        discrete (bool, bool): Whether x or y are discrete.\n",
    "        plot_return (bool): If True, return statistics useful for plotting.\n",
    "        verbose (bool): Print out progress messages (or not).\n",
    "        cv_grid (list): cv params\n",
    "    Returns:\n",
    "        p (float): The p-value for the null hypothesis\n",
    "            that x is independent of y.\n",
    "    \"\"\"\n",
    "    ###################################################\n",
    "    # Compute test set size.\n",
    "    n_samples = x.shape[0]\n",
    "    n_test = int(n_samples * prop_test)\n",
    "\n",
    "    if z is None:\n",
    "        z = np.empty([n_samples, 0])\n",
    "\n",
    "    if discrete[0] and not discrete[1]:\n",
    "        # If x xor y is discrete, use the continuous variable as input.\n",
    "        x, y = y, x\n",
    "    elif x.shape[1] < y.shape[1]:\n",
    "        # Otherwise, predict the variable with fewer dimensions.\n",
    "        x, y = y, x\n",
    "        \n",
    "    # Normalize y to make the decision tree stopping criterion meaningful.\n",
    "    y = StandardScaler().fit_transform(y)\n",
    "    \n",
    "    # Set up storage for true data and permuted data MSEs.\n",
    "    d0_stats = np.zeros(num_perm)\n",
    "    d1_stats = np.zeros(num_perm)\n",
    "    data_permutations = [np.random.permutation(n_samples) for i in range(num_perm)]\n",
    "    \n",
    "    ########################################################\n",
    "    # Compute mses for y = f(x, z), varying train-test splits.\n",
    "    clf = cross_val(x, y, z, cv_grid, verbose, model, prop_test=prop_test)\n",
    "    datadict = {\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'z': z,\n",
    "            'data_permutation': data_permutations,\n",
    "            'n_test': n_test,\n",
    "            'reshuffle': False,\n",
    "            'clf': clf,\n",
    "            }\n",
    "    d1_stats = np.array(joblib.Parallel(n_jobs=-1, max_nbytes=100e6)(\n",
    "        joblib.delayed(obtain_error)((datadict, i)) for i in range(num_perm)))\n",
    "\n",
    "    \n",
    "    #####################################################################33\n",
    "    # Compute mses for y = f(x, reshuffle(z)), varying train-test splits.\n",
    "    if z.shape[1] == 0:\n",
    "        x_indep_y = x[np.random.permutation(n_samples)]\n",
    "    else:\n",
    "        x_indep_y = np.empty([x.shape[0], 0])\n",
    "        \n",
    "        \n",
    "    clf = cross_val(x_indep_y, y, z, cv_grid, verbose, model, prop_test=prop_test)\n",
    "    \n",
    "    datadict['reshuffle'] = True\n",
    "    datadict['x'] = x_indep_y\n",
    "    d0_stats = np.array(joblib.Parallel(n_jobs=-1, max_nbytes=100e6)(\n",
    "        joblib.delayed(obtain_error)((datadict, i)) for i in range(num_perm)))\n",
    "\n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        np.set_printoptions(precision=3)\n",
    "        print('D0 statistics: {}'.format(d0_stats))\n",
    "        print('D1 statistics: {}\\n'.format(d1_stats))\n",
    "\n",
    "        \n",
    "    #######################################################33    \n",
    "    # Compute the p-value (one-tailed t-test\n",
    "    # that mean of mse ratios equals 1) <- default, o.w. use k-sample.\n",
    "    \n",
    "    \n",
    "    if not ksamp_test:\n",
    "        t, p_value = ttest_1samp(d0_stats / d1_stats, 1)\n",
    "        if t < 0:\n",
    "            p_value = 1 - p_value / 2\n",
    "        else:\n",
    "            p_value = p_value / 2\n",
    "\n",
    "        if plot_return:\n",
    "            return (p_value, d0_stats, d1_stats)\n",
    "        else:\n",
    "            return p_value\n",
    "    else:\n",
    "        _, p_value = ksamp_test.test(d0_stats, d1_stats)\n",
    "        \n",
    "        return p_value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pval_i:  0.7935615455689975\n",
      "pval_d:  0.000806704561203216\n"
     ]
    }
   ],
   "source": [
    "#Using random forest\n",
    "x = np.random.rand(1000, 1)\n",
    "y = np.random.randn(1000, 1)\n",
    "\n",
    "pval_i = test(x, y, model=DecisionTreeRegressor(), cv_grid={'min_samples_split': [2, 8, 64, 512, 1e-2, .2, .4]\n",
    "                                                           }) # p-value should be uniform on [0, 1].\n",
    "pval_d = test(x, x + y, model=DecisionTreeRegressor(), cv_grid={'min_samples_split': [2, 8, 64, 512, 1e-2, .2, .4]\n",
    "                                                               }) # p-value should be very small.\n",
    "\n",
    "\n",
    "print(\"pval_i: \", pval_i)\n",
    "print(\"pval_d: \", pval_d) # as expected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pval_i:  0.2702456956045596\n",
      "pval_d:  0.00014121915198302544\n"
     ]
    }
   ],
   "source": [
    "#Using linear regression\n",
    "\n",
    "x = np.random.rand(1000, 1)\n",
    "y = np.random.randn(1000, 1)\n",
    "\n",
    "pval_i = test(x, y, model=LinearRegression(), cv_grid={'fit_intercept': [True, False]\n",
    "                                                           }) # p-value should be uniform on [0, 1].\n",
    "pval_d = test(x, x + y, model=LinearRegression(), cv_grid={'fit_intercept': [True, False]\n",
    "                                                               }) # p-value should be very small.\n",
    "\n",
    "\n",
    "print(\"pval_i: \", pval_i)\n",
    "print(\"pval_d: \", pval_d) # as expected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pval_i:  0.905836144033228\n",
      "pval_d:  0.6849204236328906\n"
     ]
    }
   ],
   "source": [
    "#Using random forest\n",
    "x = np.random.rand(1000, 1)\n",
    "y = np.random.randn(1000, 1)\n",
    "\n",
    "\n",
    "k = Hotelling()\n",
    "\n",
    "pval_i = test(x, y, model=DecisionTreeRegressor(), ksamp_test=k, \n",
    "              cv_grid={'min_samples_split': [2, 8, 64, 512, 1e-2, .2, .4]}) \n",
    "\n",
    "\n",
    "pval_d = test(x, x + y, model=DecisionTreeRegressor(), ksamp_test=k,\n",
    "              cv_grid={'min_samples_split': [2, 8, 64, 512, 1e-2, .2, .4]})\n",
    "\n",
    "\n",
    "print(\"pval_i: \", pval_i)\n",
    "print(\"pval_d: \", pval_d) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
