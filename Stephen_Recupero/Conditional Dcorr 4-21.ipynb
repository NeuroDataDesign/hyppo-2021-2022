{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4802d731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances, pairwise_kernels\n",
    "from hyppo.tools import compute_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccfda624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ndarray_xyz(x, y,z):\n",
    "    \"\"\"Check if x, y, or z is an ndarray of float\"\"\"\n",
    "    if not isinstance(x, np.ndarray) or not isinstance(y, np.ndarray) or not isinstance(z, np.ndarray):\n",
    "        raise TypeError(\"x, y, and z must be ndarrays\")\n",
    "\n",
    "def convert_xyz_float64(x, y, z):\n",
    "    \"\"\"Convert x or y, or z to np.float64 (if not already done)\"\"\"\n",
    "    # convert x and y to floats\n",
    "    x = np.asarray(x).astype(np.float64)\n",
    "    y = np.asarray(y).astype(np.float64)\n",
    "    z = np.asarray(z).astype(np.float64)\n",
    "\n",
    "    return x, y, z\n",
    "\n",
    "                        \n",
    "class _CheckInputs:\n",
    "    \"\"\"Checks inputs for all independence tests\"\"\"\n",
    "\n",
    "    def __init__(self, x, y,z, reps=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        self.reps = reps\n",
    "\n",
    "    def __call__(self):\n",
    "        check_ndarray_xy(self.x, self.y, self.z)\n",
    "        contains_nan(self.x)\n",
    "        contains_nan(self.y)\n",
    "        contains_nan(self.z)\n",
    "        self.x, self.y, self.z = self.check_dim_xy()\n",
    "        self.x, self.y = convert_xyz_float64(self.x, self.y, self.z)\n",
    "        self._check_min_samples()\n",
    "        self._check_variance()\n",
    "\n",
    "        if self.reps:\n",
    "            check_reps(self.reps)\n",
    "\n",
    "        return self.x, self.y, self.z\n",
    "    def _check_min_samples(self):\n",
    "        \"\"\"Check if the number of samples is at least 3\"\"\"\n",
    "        nx = self.x.shape[0]\n",
    "        ny = self.y.shape[0]\n",
    "        nz = self.z.shape[0]\n",
    "\n",
    "        if nx <= 3 or ny <= 3 or nz <= 3:\n",
    "            raise ValueError(\"Number of samples is too low\")\n",
    "    \n",
    "    def check_dim_xyz(self):\n",
    "        \"\"\"Convert x and y and z to proper dimensions\"\"\"\n",
    "        if self.x.ndim == 1:\n",
    "            self.x = self.x[:, np.newaxis]\n",
    "        elif self.x.ndim != 2:\n",
    "            raise ValueError(\n",
    "                \"Expected a 2-D array `x`, found shape \" \"{}\".format(self.x.shape)\n",
    "            )\n",
    "        if self.y.ndim == 1:\n",
    "            self.y = self.y[:, np.newaxis]\n",
    "        elif self.y.ndim != 2:\n",
    "            raise ValueError(\n",
    "                \"Expected a 2-D array `y`, found shape \" \"{}\".format(self.y.shape)\n",
    "            )\n",
    "        if self.z.ndim == 1:\n",
    "            self.z = self.z[:, np.newaxis]\n",
    "        elif self.z.ndim != 2:\n",
    "            raise ValueError(\n",
    "                \"Expected a 2-D array `z`, found shape \" \"{}\".format(self.z.shape)\n",
    "            )\n",
    "        return self.x, self.y, self.z\n",
    "                \n",
    "    def _check_variance(self):\n",
    "        if np.var(self.x) == 0 or np.var(self.y) == 0 or np.var(self.z) == 0:\n",
    "            raise ValueError(\"Test cannot be run, one of the inputs has 0 variance\")\n",
    "                \n",
    "\n",
    "def conditional_dcorr(x,y,z,kernel_type, seed, reps = 1000, num_bootstrap = 99):\n",
    "    check_input = _CheckInputs(\n",
    "            x,\n",
    "            y,\n",
    "            z,\n",
    "            reps=reps\n",
    "        )\n",
    "    x, y,z = check_input()\n",
    "    #unsure of how to check z as check_input takes two inputs\n",
    "    distx, disty = compute_dist(\n",
    "                x, y, metric=\"euclidean\")\n",
    "    kernel_density_estimation = pairwise_kernels(z, metric=kernel_type, n_jobs=1)\n",
    "    stat = Statistic(distx, disty, kernel_density_estimation)\n",
    "    pvalue = conduct_cdc_test(dist_x, dist_y, kernel_density_estimation, num_bootstrap, seed, stat)\n",
    "    return stat, pvalue\n",
    "\n",
    "def Statistic(distx, disty, kernel_density_estimation):\n",
    "    return condition_distance_correlation_stats(distance_x, distance_y, kernel_density_estimation)\n",
    "                \n",
    "def condition_distance_correlation_stats(distance_x, distance_y, kernel_density_estimation):\n",
    "    condition_distance_correlation = compute_condition_distance_correlation(distance_x, \n",
    "                                                                            distance_y,kernel_density_estimation)\n",
    "    return np.mean(condition_distance_correlation)\n",
    "\n",
    "def compute_condition_distance_correlation(distance_x, distance_y,kernel_density_estimation):\n",
    "\n",
    "    num = distance_x.size()\n",
    "    anova_x = np.zeros((num,num))\n",
    "    anova_y = np.zeros((num,num))\n",
    "    condition_distance_covariance_xy = np.zeros(num)\n",
    "    condition_distance_covariance_xx = np.zeros(num)\n",
    "    condition_distance_covariance_yy = np.zeros(num)\n",
    "\n",
    "    for i in range(num):\n",
    "        anova_x = weight_distance_anova(distance_x, kernel_density_estimation[i])\n",
    "        anova_y = weight_distance_anova(distance_y, kernel_density_estimation[i])\n",
    "\n",
    "        for k in range(num):\n",
    "            for j in range(num): \n",
    "                condition_distance_covariance_xy[i] += anova_x[k][j] * anova_y[k][j] * kernel_density_estimation[i][k] * kernel_density_estimation[i][j]\n",
    "                condition_distance_covariance_xx[i] += anova_x[k][j] * anova_x[k][j] * kernel_density_estimation[i][k] * kernel_density_estimation[i][j]\n",
    "                condition_distance_covariance_yy[i] += anova_y[k][j] * anova_y[k][j] * kernel_density_estimation[i][k] * kernel_density_estimation[i][j]\n",
    "    for i in range(num):\n",
    "        dcor_denominator = condition_distance_covariance_xx[i] * condition_distance_covariance_yy[i]\n",
    "        if (dcor_denominator > 0.0):\n",
    "            condition_distance_covariance_xy[i] /= np.sqrt(dcor_denominator)\n",
    "        else:\n",
    "            condition_distance_covariance_xy[i] = 0.0\n",
    "\n",
    "    return condition_distance_covariance_xy \n",
    "\n",
    "def weight_distance_anova(distance_matrix, weight):\n",
    "    weight_sum = np.sum(weight)\n",
    "    num = distance_matrix.size()\n",
    "\n",
    "    marginal_weight_distance = np.zeros(num)\n",
    "    for i in range(num):\n",
    "        marginal_weight_distance[i] = vector_weight_sum(distance_matrix[i], weight)\n",
    "    \n",
    "    weight_distance_sum = vector_weight_sum(marginal_weight_distance, weight) \n",
    "    weight_distance_sum /= weight_sum * weight_sum\n",
    "\n",
    "    for i in range(num):\n",
    "        marginal_weight_distance[i] /= weight_sum\n",
    "\n",
    "    weight_distance_anova_table = np.zeros((num,num))\n",
    "    for k in range(num):\n",
    "        for j in range(num):\n",
    "            weight_distance_anova_table[k][j] = distance_matrix[k][j] - marginal_weight_distance[k] - marginal_weight_distance[j] + weight_distance_sum\n",
    "            weight_distance_anova_table[j][k] = weight_distance_anova_table[k][j]\n",
    "\n",
    "    return weight_distance_anova_table\n",
    "\n",
    "def vector_weight_sum(vector1, weight): \n",
    "    sum_value = 0.0\n",
    "    for i in range(vector1.size()):\n",
    "        sum_value += vector1[i] * weight[i]\n",
    "    return sum_value\n",
    "\n",
    "def conduct_cdc_test(distance_x, distance_y, kernel, num_bootstrap, seed, stat):\n",
    "\n",
    "    if (num_bootstrap != 0):\n",
    "        if (seed == 0):\n",
    "            rng = np.random.default_rng()\n",
    "        else:\n",
    "            rng = np.random.default_rng(seed)\n",
    "\n",
    "        random_sample_index = generate_random_sample_index(num_bootstrap, kernel,rng)\n",
    "\n",
    "        bootstrap_distance_x = []\n",
    "        perm_stat = np.zeros(num_bootstrap)\n",
    "        for i in range(num_bootstrap):\n",
    "            bootstrap_distance_x = rearrange_matrix(distance_x, random_sample_index[i])\n",
    "            perm_stat[i] = Statistic(bootstrap_distance_x, distance_y, kernel)\n",
    "        \n",
    "        p_value = compute_p_value(perm_stat, stat);\n",
    "        return p_value\n",
    "\n",
    "def compute_p_value( permuted_statistic, statistic):\n",
    "        larger_num = 0.0\n",
    "        for value in  permuted_statistic:\n",
    "            larger_num += value >= statistic\n",
    "        return (1.0 + larger_num) / (1.0 + permuted_statistic.size().astype(float))\n",
    "    \n",
    "def rearrange_matrix(dist_matrix,rearrange_index):\n",
    "    new_matrix1 = np.zeros((rearrange_index.size(),rearrange_index.size()))\n",
    "    new_matrix2 = np.zeros((rearrange_index.size(),rearrange_index.size()))\n",
    "    k = 0\n",
    "    for index in rearrange_index:\n",
    "        new_matrix1[k] = dist_matrix[index]\n",
    "        new_matrix2[k] = dist_matrix[index]\n",
    "        k = k+ 1\n",
    "    \n",
    "    k = 0\n",
    "    for index in rearrance_index:\n",
    "        for i in range(dist_matrix.size()):\n",
    "            new_matrix1[i][k] = new_matrix2[i][index];\n",
    "        k = k+1\n",
    "    \n",
    "    return new_matrix1\n",
    "\n",
    "def generate_random_sample_index(replication_number, probability_matrix,random_number_generator):\n",
    "    random_sample_index = np.zeros((replication_number,probability_matrix.size()))\n",
    "    for i in range(probability_matrix.size()):\n",
    "        for j in range(replication_number):\n",
    "            random_sample_index[j][i] = sample_multinomial_distribution(probability_matrix[i], random_number_generator)\n",
    "    return random_sample_index;\n",
    "\n",
    "def sample_mulitnomial_distribution(prob_array, random_number_generator):\n",
    "    arr = random_number_generator.multinomial(1,prob_array)\n",
    "    index = np.where(arr == 1)\n",
    "    return index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01b57be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
