{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e5e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances, pairwise_kernels\n",
    "from sklearn.utils import check_random_state\n",
    "from hyppo.tools import compute_dist, check_perm_blocks, check_perm_block, contains_nan, check_reps\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "230926b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ndarray_xyz(x, y,z):\n",
    "    \"\"\"Check if x, y, or z is an ndarray of float\"\"\"\n",
    "    if not isinstance(x, np.ndarray) or not isinstance(y, np.ndarray) or not isinstance(z, np.ndarray):\n",
    "        raise TypeError(\"x, y, and z must be ndarrays\")\n",
    "\n",
    "def convert_xyz_float64(x, y, z):\n",
    "    \"\"\"Convert x or y, or z to np.float64 (if not already done)\"\"\"\n",
    "    # convert x and y to floats\n",
    "    x = np.asarray(x).astype(np.float64)\n",
    "    y = np.asarray(y).astype(np.float64)\n",
    "    z = np.asarray(z).astype(np.float64)\n",
    "\n",
    "    return x, y, z\n",
    "\n",
    "                        \n",
    "class _CheckInputs:\n",
    "    \"\"\"Checks inputs for all independence tests\"\"\"\n",
    "\n",
    "    def __init__(self, x, y,z, reps=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        self.reps = reps\n",
    "\n",
    "    def __call__(self):\n",
    "        check_ndarray_xyz(self.x, self.y, self.z)\n",
    "        contains_nan(self.x)\n",
    "        contains_nan(self.y)\n",
    "        contains_nan(self.z)\n",
    "        self.x, self.y, self.z = self.check_dim_xyz()\n",
    "        self.x, self.y, self.z = convert_xyz_float64(self.x, self.y, self.z)\n",
    "        self._check_min_samples()\n",
    "        self._check_variance()\n",
    "\n",
    "        if self.reps:\n",
    "            check_reps(self.reps)\n",
    "\n",
    "        return self.x, self.y, self.z\n",
    "    def _check_min_samples(self):\n",
    "        \"\"\"Check if the number of samples is at least 3\"\"\"\n",
    "        nx = self.x.shape[0]\n",
    "        ny = self.y.shape[0]\n",
    "        nz = self.z.shape[0]\n",
    "\n",
    "        if nx <= 3 or ny <= 3 or nz <= 3:\n",
    "            raise ValueError(\"Number of samples is too low\")\n",
    "    \n",
    "    def check_dim_xyz(self):\n",
    "        \"\"\"Convert x and y and z to proper dimensions\"\"\"\n",
    "        if self.x.ndim == 1:\n",
    "            self.x = self.x[:, np.newaxis]\n",
    "        elif self.x.ndim != 2:\n",
    "            raise ValueError(\n",
    "                \"Expected a 2-D array `x`, found shape \" \"{}\".format(self.x.shape)\n",
    "            )\n",
    "        if self.y.ndim == 1:\n",
    "            self.y = self.y[:, np.newaxis]\n",
    "        elif self.y.ndim != 2:\n",
    "            raise ValueError(\n",
    "                \"Expected a 2-D array `y`, found shape \" \"{}\".format(self.y.shape)\n",
    "            )\n",
    "        if self.z.ndim == 1:\n",
    "            self.z = self.z[:, np.newaxis]\n",
    "        elif self.z.ndim != 2:\n",
    "            raise ValueError(\n",
    "                \"Expected a 2-D array `z`, found shape \" \"{}\".format(self.z.shape)\n",
    "            )\n",
    "        return self.x, self.y, self.z\n",
    "                \n",
    "    def _check_variance(self):\n",
    "        if np.var(self.x) == 0 or np.var(self.y) == 0 or np.var(self.z) == 0:\n",
    "            raise ValueError(\"Test cannot be run, one of the inputs has 0 variance\")\n",
    "                \n",
    "\n",
    "def conditional_dcorr(x,y,z,kernel_type, reps = 1000, workers = 1,   is_distsim=True,\n",
    "        perm_blocks=None,\n",
    "        random_state=None):\n",
    "    check_input = _CheckInputs(\n",
    "            x,\n",
    "            y,\n",
    "            z,\n",
    "            reps=reps\n",
    "        )\n",
    "    x, y,z = check_input()\n",
    "    #unsure of how to check z as check_input takes two inputs\n",
    "    distx, disty = compute_dist(\n",
    "                x, y, metric=\"euclidean\")\n",
    "    kernel_density_estimation = pairwise_kernels(z, metric=kernel_type, n_jobs=1)\n",
    "    stat, pvalue, null_dist = perm_test(Statistic, distx, disty,kernel_density_estimation,reps,workers,is_distsim,perm_blocks,random_state)\n",
    "    return stat, pvalue\n",
    "\n",
    "def Statistic(distx,disty,kernel_density_estimation):\n",
    "\n",
    "    return condition_distance_correlation_stats(distx, disty, kernel_density_estimation)\n",
    "                \n",
    "def condition_distance_correlation_stats(distance_x, distance_y, kernel_density_estimation):\n",
    "    condition_distance_correlation = compute_condition_distance_correlation(distance_x, \n",
    "                                                                            distance_y,kernel_density_estimation)\n",
    "    return np.mean(condition_distance_correlation)\n",
    "\n",
    "def compute_condition_distance_correlation(distance_x, distance_y,kernel_density_estimation):\n",
    "\n",
    "    num = distance_x.shape[0]\n",
    "    anova_x = np.zeros((num,num))\n",
    "    anova_y = np.zeros((num,num))\n",
    "    condition_distance_covariance_xy = np.zeros(num)\n",
    "    condition_distance_covariance_xx = np.zeros(num)\n",
    "    condition_distance_covariance_yy = np.zeros(num)\n",
    "\n",
    "    for i in range(num):\n",
    "        anova_x = weight_distance_anova(distance_x, kernel_density_estimation[i])\n",
    "        anova_y = weight_distance_anova(distance_y, kernel_density_estimation[i])\n",
    "\n",
    "        for k in range(num):\n",
    "            for j in range(num): \n",
    "                condition_distance_covariance_xy[i] += anova_x[k][j] * anova_y[k][j] * kernel_density_estimation[i][k] * kernel_density_estimation[i][j]\n",
    "                condition_distance_covariance_xx[i] += anova_x[k][j] * anova_x[k][j] * kernel_density_estimation[i][k] * kernel_density_estimation[i][j]\n",
    "                condition_distance_covariance_yy[i] += anova_y[k][j] * anova_y[k][j] * kernel_density_estimation[i][k] * kernel_density_estimation[i][j]\n",
    "    for i in range(num):\n",
    "        dcor_denominator = condition_distance_covariance_xx[i] * condition_distance_covariance_yy[i]\n",
    "        if (dcor_denominator > 0.0):\n",
    "            condition_distance_covariance_xy[i] /= np.sqrt(dcor_denominator)\n",
    "        else:\n",
    "            condition_distance_covariance_xy[i] = 0.0\n",
    "\n",
    "    return condition_distance_covariance_xy \n",
    "\n",
    "def weight_distance_anova(distance_matrix, weight):\n",
    "    weight_sum = np.sum(weight)\n",
    "    num = distance_matrix.shape[0]\n",
    "\n",
    "    marginal_weight_distance = np.zeros(num)\n",
    "    for i in range(num):\n",
    "        marginal_weight_distance[i] = vector_weight_sum(distance_matrix[i], weight)\n",
    "    weight_distance_sum = vector_weight_sum(marginal_weight_distance, weight) \n",
    "    weight_distance_sum /= weight_sum * weight_sum\n",
    "\n",
    "    for i in range(num):\n",
    "        marginal_weight_distance[i] /= weight_sum\n",
    "\n",
    "    weight_distance_anova_table = np.zeros((num,num))\n",
    "    for k in range(num):\n",
    "        for j in range(num):\n",
    "            weight_distance_anova_table[k][j] = distance_matrix[k][j] - marginal_weight_distance[k] - marginal_weight_distance[j] + weight_distance_sum\n",
    "            weight_distance_anova_table[j][k] = weight_distance_anova_table[k][j]\n",
    "\n",
    "    return weight_distance_anova_table\n",
    "\n",
    "def vector_weight_sum(vector1, weight): \n",
    "    sum_value = 0.0\n",
    "    for i in range(vector1.shape[0]):\n",
    "        sum_value += vector1[i] * weight[i]\n",
    "    return sum_value\n",
    "\n",
    "\n",
    "class _PermNode(object):\n",
    "    \"\"\"Helper class for nodes in _PermTree.\"\"\"\n",
    "\n",
    "    def __init__(self, parent, label=None, index=None):\n",
    "        self.children = []\n",
    "        self.parent = parent\n",
    "        self.label = label\n",
    "        self.index = index\n",
    "\n",
    "    def get_leaf_indices(self):\n",
    "        if len(self.children) == 0:\n",
    "            return [self.index]\n",
    "        else:\n",
    "            indices = []\n",
    "            for child in self.children:\n",
    "                indices += child.get_leaf_indices()\n",
    "            return indices\n",
    "\n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)\n",
    "\n",
    "    def get_children(self):\n",
    "        return self.children\n",
    "\n",
    "\n",
    "\n",
    "class _PermTree(object):\n",
    "    \"\"\"Tree representation of dependencies for restricted permutations\"\"\"\n",
    "\n",
    "    def __init__(self, perm_blocks):\n",
    "        perm_blocks = check_perm_blocks(perm_blocks)\n",
    "        self.root = _PermNode(None)\n",
    "        self._add_levels(self.root, perm_blocks, np.arange(perm_blocks.shape[0]))\n",
    "        indices = self.root.get_leaf_indices()\n",
    "        self._index_order = np.argsort(indices)\n",
    "\n",
    "    def _add_levels(self, root: _PermNode, perm_blocks, indices):\n",
    "        # Add new child node for each unique label, then recurse or end\n",
    "        if perm_blocks.shape[1] == 0:\n",
    "            for idx in indices:\n",
    "                child_node = _PermNode(parent=root, label=1, index=idx)\n",
    "                root.add_child(child_node)\n",
    "        else:\n",
    "            perm_block = check_perm_block(perm_blocks[:, 0])\n",
    "            for label in np.unique(perm_block):\n",
    "                idxs = np.where(perm_block == label)[0]\n",
    "                child_node = _PermNode(parent=root, label=label)\n",
    "                root.add_child(child_node)\n",
    "                self._add_levels(child_node, perm_blocks[idxs, 1:], indices[idxs])\n",
    "\n",
    "    def _permute_level(self, node, rng=None):\n",
    "        if rng is None:\n",
    "            rng = np.random\n",
    "        if len(node.get_children()) == 0:\n",
    "            return [node.index]\n",
    "        else:\n",
    "            indices, labels = zip(\n",
    "                *[\n",
    "                    (self._permute_level(child), child.label)\n",
    "                    for child in node.get_children()\n",
    "                ]\n",
    "            )\n",
    "            shuffle_children = [i for i, label in enumerate(labels) if label >= 0]\n",
    "            indices = np.asarray(indices)\n",
    "            if len(shuffle_children) > 1:\n",
    "                indices[shuffle_children] = indices[rng.permutation(shuffle_children)]\n",
    "            return np.concatenate(indices)\n",
    "\n",
    "    def permute_indices(self, rng=None):\n",
    "        return self._permute_level(self.root, rng)[self._index_order]\n",
    "\n",
    "    def original_indices(self):\n",
    "        return np.arange(len(self._index_order))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class _PermGroups(object):\n",
    "    \"\"\"Helper function to calculate parallel p-value.\"\"\"\n",
    "\n",
    "    def __init__(self, x, perm_blocks=None):\n",
    "        self.n = x.shape[0]\n",
    "        if perm_blocks is None:\n",
    "            self.perm_tree = None\n",
    "        else:\n",
    "            self.perm_tree = _PermTree(perm_blocks)\n",
    "\n",
    "    def __call__(self, rng=None):\n",
    "        if rng is None:\n",
    "            rng = np.random\n",
    "        if self.perm_tree is None:\n",
    "            order = rng.permutation(self.n)\n",
    "        else:\n",
    "            order = self.perm_tree.permute_indices(rng)\n",
    "\n",
    "        return order\n",
    "\n",
    "\n",
    "def _perm_stat(calc_stat, x, y, kernel_density_estimation, is_distsim=True, permuter=None, random_state=None):\n",
    "    \"\"\"Permute the test statistic\"\"\"\n",
    "    rng = check_random_state(random_state)\n",
    "    if permuter is None:\n",
    "        order = rng.permutation(x.shape[0])\n",
    "    else:\n",
    "        order = permuter(rng)\n",
    "\n",
    "    if is_distsim:\n",
    "        permx = x[order][:, order]\n",
    "    else:\n",
    "        permx = x[order]\n",
    "\n",
    "    perm_stat = calc_stat(permx, y, kernel_density_estimation)\n",
    "\n",
    "    return perm_stat\n",
    "\n",
    "def perm_test(\n",
    "    calc_stat,\n",
    "    x,\n",
    "    y,\n",
    "    kernel_density_estimation,\n",
    "    reps=1000,\n",
    "    workers=1,\n",
    "    is_distsim=True,\n",
    "    perm_blocks=None,\n",
    "    random_state=None):\n",
    "    \n",
    "    # calculate observed test statistic\n",
    "    stat = calc_stat(x, y, kernel_density_estimation)\n",
    "\n",
    "    # make RandomState seeded array\n",
    "    if random_state is not None:\n",
    "        rng = check_random_state(random_state)\n",
    "        random_state = rng.randint(np.iinfo(np.int32).max, size=reps)\n",
    "\n",
    "    # make random array\n",
    "    else:\n",
    "        random_state = np.random.randint(np.iinfo(np.int32).max, size=reps)\n",
    "\n",
    "    # calculate null distribution\n",
    "    permuter = _PermGroups(x, perm_blocks)\n",
    "\n",
    "    null_dist = np.array(\n",
    "        Parallel(n_jobs=workers)(\n",
    "            [\n",
    "                delayed(_perm_stat)(calc_stat, x, y, kernel_density_estimation, is_distsim, permuter, rng)\n",
    "                for rng in random_state\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    pvalue = (1 + (null_dist >= stat).sum()) / (1 + reps)\n",
    "\n",
    "    return stat, pvalue, null_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf675e43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
