{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multiscale_graphcorr\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy._lib._util import MapWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_sample_test(X, y,score_func):\n",
    "    one_hot_enc = OneHotEncoder() #onehotencoding\n",
    "    temp =  one_hot_enc.fit_transform(y.reshape(-1,1))\n",
    "    y = temp.toarray()\n",
    "    if score_func == \"mgc\":\n",
    "        mgc = multiscale_graphcorr(X,y)\n",
    "        stat = mgc.stat #mgc case\n",
    "    else: \n",
    "        mgc = multiscale_graphcorr(X,y)\n",
    "        stat = mgc.stat#default is mgc as no other tests in scipy\n",
    "    return(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_transform(X,y,k,score_func):\n",
    "    features = X.shape[1] #features of matrix X(n samples by p features )\n",
    "    best_features = []\n",
    "    while (len(best_features) < k): # outerloop to obtain up to k features \n",
    "        j = 0 #sets inner loop equal to 0 at each iteration\n",
    "        X_new = np.array(X) # establishes matrix of data as np array\n",
    "        scores = []\n",
    "        while(j< features): #inner loop to find the next best feature relative to features already obtained\n",
    "            if len(best_features) == 0: #in case where we are obtaining first feature, we perform calculation in this way\n",
    "                X_j =  X_new[:,j] #each feature from j to last feature \n",
    "                stat= k_sample_test(X_j,y,score_func) #multivariate independence test performed on each feature\n",
    "                scores.append(stat)#stat obtained, in first feature case we select the best single feature\n",
    "            else:\n",
    "                if j not in best_features:\n",
    "                    columns = best_features #construct array for indexing \n",
    "                    columns.append(j)\n",
    "                    columns = np.sort(columns)\n",
    "                    X_j = X_new[:,columns] #perform test with obtained features against every feature after to then obtain the best group of features with one additional feature \n",
    "                    stat= k_sample_test(X_j,y,score_func)\n",
    "                    scores.append(stat)\n",
    "            j =j +1\n",
    "        sorted_index = np.argsort(scores)\n",
    "        best = sorted_index[len(scores)-1] #find best of the scores\n",
    "        best_features.append(best)\n",
    "    return X_new[:,best_features] # obtain the first k feature columns as we have constructed those to be approximately the best k features as a group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_transform_p(X,y,k,score_func,workers = -1): \n",
    "    features = range(X.shape[1])#features of matrix X(n samples by p features, creates an array of feature indexes\n",
    "    best_features = []\n",
    "    while (len(best_features) < k): # outerloop to obtain up to k features \n",
    "        X_new = np.array(X)# establishes matrix of data as np array\n",
    "        parallel = _Parallel(X_new=X_new, y=y, score_func = score_func,best_features = best_features) #establishes parallel operation helper class object\n",
    "        with MapWrapper(workers) as mapwrapper:\n",
    "            scores = list(mapwrapper(parallel, features)) #maps in parallel the parallel operation that calcs score with the iterable features list to test, with best_features already obtained\n",
    "        scores_index = np.zeros((len(features),2)) #temp array\n",
    "        scores_index[0] = features #input features as first column, all features tested(exclude best_features)\n",
    "        scores_index[1] = scores #input scores in second column\n",
    "        sorted_index = scores_index[scores_index[:, 1].argsort()] #sort by scores column\n",
    "        best = sorted_index[len(scores)-1,0] #find best of the scores\n",
    "        best_features.append(best) #append new best feature column index \n",
    "        features.remove(best)\n",
    "    return X_new[:,best_features] # obtain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Parallel:\n",
    "    \"\"\"Helper function to calculate parallel test value.\"\"\"\n",
    "\n",
    "    def __init__(self, X_new, y,score_func,best_features):\n",
    "        self.X_new = X_new\n",
    "        self.y = y\n",
    "        self.score_func = score_func\n",
    "        self.best_features = best_features\n",
    "\n",
    "    def __call__(self, index):\n",
    "        if len(best_features)==0:\n",
    "            X_j =  self.X_new[:,index] #each feature from j to last feature \n",
    "            stat= k_sample_test(X_j,self.y,self.score_func)\n",
    "        else:\n",
    "            columns = self.best_features #construct array for indexing \n",
    "            columns.append(index)\n",
    "            X_j = self.X_new[:,columns] #perform test with obtained features against every feature after to then obtain the best group of features with one additional feature \n",
    "            stat= k_sample_test(X_j,self.y,self.score_func)\n",
    "            \n",
    "\n",
    "        return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.testing import assert_almost_equal, assert_raises\n",
    "from hyppo.ksample import KSample\n",
    "\n",
    "def k_sample_equals_shuffle(X,y,score_func):\n",
    "    X_shuffle = X[:, np.random.permutation(X.shape[1])]\n",
    "    assert_almost_equal(k_sample_test(X,y,score_func), k_sample_test(X_shuffle,y,score_func), decimal=1)\n",
    "#case k = 3\n",
    "def k_sample_equals_k_matrix_K_Sample(X,y,score_func):\n",
    "    k = len(np.unique(y))\n",
    "    matrices = []\n",
    "    i = 0\n",
    "    while i <k:\n",
    "        indices = np.where(y == i)[0] \n",
    "        xi = X[indices,:]\n",
    "        matrices.append(xi)\n",
    "        i = i + 1\n",
    "    true_stat,true_pvalue,_ = KSample(\"MGC\").test(matrices[0],matrices[1],matrices[2])\n",
    "    assert_almost_equal(k_sample_test(X,y,score_func), true_stat, decimal=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Run test functions\n",
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "print(k_sample_equals_shuffle(X,y,\"mgc\"))\n",
    "\n",
    "print(k_sample_equals_k_matrix_K_Sample(X,y,\"mgc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
