{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.feature_selection import SelectorMixin\n",
    "import numpy as np\n",
    "from scipy.stats import multiscale_graphcorr\n",
    "from scipy.sparse import isspmatrix\n",
    "import warnings\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def k_sample_test(X,y, score_func = 'mgc'):    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    mgc = multiscale_graphcorr(X,y,reps = 0)\n",
    "    stat = mgc.stat\n",
    "    return stat\n",
    "\n",
    "class MultivariateFeatureSelector(SelectorMixin, BaseEstimator):\n",
    "    \"\"\" Transformer that performs forward selection.\n",
    "    \n",
    "    This feature selector adds features (forward selection) to\n",
    "    form a feature subset. At each iteration, a parallel \n",
    "    operation occurs in which a multivariate independence test \n",
    "    is performed for each data matrix with the selected best \n",
    "    features and an additional feature not yet selected. The \n",
    "    additional feature associated with the highest multivariate\n",
    "    independence test statistic is then chosen as the next best \n",
    "    feature. \n",
    "    \n",
    "    Read more in the :ref:`User Guide <multivariate_feature_selection>`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    k: int, default=10\n",
    "        amount of features to select. \n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    features_ : array, shape (n_features,)\n",
    "        indices of all features in X\n",
    "    \n",
    "    best_features_ : array, shape (k,)\n",
    "         indices of selected k best features of features_\n",
    "         \n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_digits\n",
    "    >>> from sklearn.feature_selection import MultivariateFeatureSelector\n",
    "    >>> X, y = load_digits(return_X_y=True)\n",
    "    >>> X.shape\n",
    "    (1797, 64)\n",
    "    >>> X_new = MultivariateFeatureSelector(k = 7).fit_transform(X, y)\n",
    "    >>> X_new.shape\n",
    "    (1797, 7)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k=10):\n",
    "        self.k = k\n",
    "        \n",
    "    def _test_stat(self, X_new, y, best_features, index):\n",
    "        # helper function for calculating, in parallel, \n",
    "        # test statistic associated with\n",
    "        # selected best features and an additional feature \n",
    "        if np.var(X_new[:,index]) == 0:\n",
    "            stat = -1.0\n",
    "        else:   \n",
    "            columns = best_features.copy() \n",
    "            columns.append(index)\n",
    "            X_j = X_new[:,columns]\n",
    "            stat = k_sample_test(X_j,y)\n",
    "        return stat\n",
    "    \n",
    "    def k_sample(X, y):\n",
    "        k_array = np.unique(y)\n",
    "        matrices = []\n",
    "        for i in k_array:\n",
    "            indices = np.where(y == i)[0] \n",
    "            if len(X.shape) == 1:\n",
    "                xi = X[indices]\n",
    "            else:\n",
    "                xi = X[indices,:]\n",
    "            matrices.append(xi)\n",
    "        X = np.concatenate(matrices)\n",
    "        vs = []\n",
    "        for i in range(len(k_array)):\n",
    "            n = matrices[i].shape[0]\n",
    "            encode = np.zeros(shape=(n, len(matrices)))\n",
    "            encode[:, i] = np.ones(shape=n)\n",
    "            vs.append(encode)\n",
    "        y = np.concatenate(vs) #mgc case\n",
    "        return(X,y)\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y,workers = -1):\n",
    "        \"\"\"Learn the features to select from X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of predictors.\n",
    "        y : array-like of shape (n_samples,), default=None\n",
    "            Target values. \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns the instance itself.\n",
    "        \"\"\"\n",
    "        if isspmatrix(X) == True:\n",
    "            X = X.toarray()\n",
    "        \n",
    "        # array of indices that correspond to features,\n",
    "        # at each iteration, the selected best feature\n",
    "        # is removed from this array\n",
    "        features = np.arange(X.shape[1])\n",
    "        \n",
    "        if np.isnan(X).any() == True:\n",
    "            raise ValueError(\"existing multivariate independence tests in scipy do not allow nan\")\n",
    "        if type(self.k) is not int:\n",
    "            raise TypeError(\"k is type {}, must be int\".format(type(self.k)))\n",
    "        if not 0 < self.k and self.k <= X.shape[1]:\n",
    "                raise ValueError(\"k is {}, must be nonnegative <= number of features of X\".format(self.k))\n",
    "        if not X.shape[0] >= 5:\n",
    "                raise ValueError(\"number of samples is {}, must be >= 5\".format(X.shape[0]))\n",
    "        \n",
    "        # loop to select feature subset, \n",
    "        # each iteration adds next best feature as \n",
    "        # determined by the mulitivariate independence test\n",
    "        # as we rank each additional feature by statistic\n",
    "        best_features = []\n",
    "        X,y = self.k_sample(X,y)\n",
    "        while len(best_features) < self.k: \n",
    "            X_new = np.array(X)\n",
    "            \n",
    "            # Parallel process for test statistic calculations \n",
    "            # of selected best features and each additional feature.\n",
    "            # size of operations in parallel per loop iteration is \n",
    "            # n_features - len(best_features)\n",
    "            scores = list(\n",
    "                Parallel(n_jobs=workers)(\n",
    "                    [\n",
    "                        delayed(self._test_stat)(X_new,y,best_features,index)\n",
    "                        for index in features\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "            scores_index = np.column_stack((features,np.array(scores)))\n",
    "            sorted_index = scores_index[scores_index[:,1].argsort()] \n",
    "            best = int(sorted_index[len(scores)-1,0])\n",
    "            best_features.append(best) \n",
    "            features = np.delete(features,np.where(features == best)) \n",
    "        self.best_features_ = best_features\n",
    "        self.features_ = np.arange(X.shape[1])\n",
    "        return self\n",
    "    \n",
    "    def _get_support_mask(self):\n",
    "        check_is_fitted(self)\n",
    "        return  np.array([x in self.best_features_ for x in self.features_])\n",
    "    \n",
    "    def _more_tags(self):\n",
    "        return {\"allow_nan\": False,\"requires_y\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
